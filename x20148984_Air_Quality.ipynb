{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract: Air Quality [Current date to next Five Days]for the Cities using Latitude and Longitude from OpenWeatherMap API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import dns\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import time\n",
    "import pandas.io.sql as sqlio\n",
    "import psycopg2\n",
    "from pandas import json_normalize\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import io\n",
    "import json\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Variable Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URI for MongoDB\n",
    "#uri_path = \"mongodb+srv://admin:Rednaxela07@dapcluster.xrctf.mongodb.net/test\"\n",
    "#URI for Postgresql\n",
    "#uri_path1 = \"postgresql://dap-cluster.cluster-cox2kms8yan4.us-east-1.rds.amazonaws.com/DAP?user=postgres&password=y8KAJAyQHhnkkTpvIvOz\"\n",
    "#Database Name and Collection's Name\n",
    "database_name = databaseName\n",
    "existing_collection = cityTableName\n",
    "new_collection_name= airQualityTableName\n",
    "#counter\n",
    "count = 0\n",
    "#Threshold for the extraction of data from API \n",
    "delay = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Establish Connection to the MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def connect_mongodb():\n",
    "        client=mongoEngine\n",
    "        return client\n",
    "            \n",
    "##############The below code is used for Individual Development##################            \n",
    "#     try:\n",
    "#         global client\n",
    "#         #client = pymongo.MongoClient(uri_path)\n",
    "#     except pymongo.errors.ConnectionFailure:\n",
    "#         print(\"Error while connection to the database\")\n",
    "#     except pymongo.errors.InvalidURI:\n",
    "#         print(\"Trying to parse the Invaild URI\")\n",
    "#     except pymongo.errors.NetworkTimeout:\n",
    "#         print(\"The database connection has been timed out\")\n",
    "#     return client\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Check the Existence of the database and Read data from  mongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def read_mongo(client,database_name,existing_collection,new_collection_name,count,delay):\n",
    "    db = client[database_name]\n",
    "    \n",
    "    #check the existing collection is available in the database\n",
    "#     exist_col = db.list_collection_names()\n",
    "#     if existing_collection in exist_col:\n",
    "#         print(\"The Existing Collection is available in the database\")\n",
    "#     else:\n",
    "#         raise exception(f\"The Existing Collection is not available in the database: {database_name}.\")\n",
    "        \n",
    "    col= db[existing_collection]\n",
    "    \n",
    "#     #IF the collection exists already drop theexisting collection and creating the new table/collection in the Database\n",
    "#     if new_collection_name in exist_col:\n",
    "#         new_col = db[new_collection_name]\n",
    "#         new_col.drop()\n",
    "#     else:\n",
    "#         new_col = db[new_collection_name]\n",
    "    count = 0\n",
    "    tasks = []\n",
    "    #Extracting the latitude and longitude from the existing City_Population Collection\n",
    "    for i in col.find():  \n",
    "        print('count', count)\n",
    "        count+=1\n",
    "        name = i[\"name\"]\n",
    "        latitude = i[\"location\"][\"latitude\"]\n",
    "        longitude= i[\"location\"][\"longitude\"] \n",
    "        cityId=i[\"cityId\"]\n",
    "        \n",
    "        #Requesting the resposne from the API based on the latitude and longitude\n",
    "        #API URL\n",
    "        url =(f'http://api.openweathermap.org/data/2.5/air_pollution/forecast?lat={latitude}&lon={longitude}&appid=f7b57c204082040afc460167c2a07941')\n",
    "        tasks.append(asyncio.ensure_future(fetch_air_quality_data(url, new_col, latitude, longitude, cityId, name)))\n",
    "    await asyncio.gather(*tasks)\n",
    "    return new_col\n",
    "\n",
    "async def fetch_air_quality_data(url, new_col, latitude, longitude, cityId, name):\n",
    "    data = {}\n",
    "    try:\n",
    "        data = {}\n",
    "        resp = requests.get(url)\n",
    "        data = resp.json()\n",
    "        data['name']=name\n",
    "        data['latitude']=latitude\n",
    "        data['longitude']=longitude\n",
    "        data['cityId']=cityId\n",
    "        print('into insetion')\n",
    "        new_col.insert_one(data)\n",
    "    except Exception as e:\n",
    "        print('error', e)\n",
    "        await asyncio.sleep(20)\n",
    "        resp = requests.get(url)\n",
    "        new_col.insert_one(data)\n",
    "    return data\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Normalize the nested structure of the data and Performing the aggregation for hourly record of the air pollution for each latitude and longitude for 10 days , but the data we required is from current  date to next five days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(new_col):\n",
    "    #Creating a empty DataFrame to append the normalize record\n",
    "    global df \n",
    "    try:\n",
    "        df = pd.DataFrame(columns=[\"date\",\"Air_Quality_Index\",\"Carbon_Monoxide\",\"Nitrogen_Monoxide\",\"Nitrogen_dioxide\",\"Ozone\",\"Sulphur_dioxide\",\"Fine_Particles_matter\",\"Coarse_particulate_Matter\",\"Ammonia\",\"cityId\",\"name\",\"latitude\",\"longitude\"])\n",
    "        #Looping the documents from the forecast_air_qualtiy collection \n",
    "        for i in new_col.find():\n",
    "            if i['list']:\n",
    "                normalize_value = json_normalize(i['list'])\n",
    "                normalize_value.columns=[\"dt\",\"Air_Quality_Index\",\"Carbon_Monoxide\",\"Nitrogen_Monoxide\",\"Nitrogen_dioxide\",\"Ozone\",\"Sulphur_dioxide\",\"Fine_Particles_matter\",\"Coarse_particulate_Matter\",\"Ammonia\"]\n",
    "\n",
    "\n",
    "                #Converting the Unix Time to Timestamp and extracting only date for performing groupby function\n",
    "                for index,j in normalize_value.iterrows():\n",
    "                    normalize_value.loc[index,\"date\"]= datetime.datetime.fromtimestamp(int(j['dt'])).strftime('%Y-%m-%d')\n",
    "\n",
    "                #Groupby date and performing aggregation on the columns\n",
    "                normalize_value = normalize_value.groupby(\"date\").mean().reset_index()\n",
    "                #Drop the Historical Data\n",
    "                normalize_value = normalize_value.drop([0,1,2,3,4,5]).reset_index()\n",
    "                #Drop the columns which isn't Required\n",
    "                normalize_value = normalize_value.drop(['dt',\"index\"],axis=1)\n",
    "\n",
    "                #Fetching the cityID,cityName,CountryName,latitude,Longitude & Region\n",
    "                normalize_value['name'] = i['name']\n",
    "                normalize_value['cityId']=i['cityId']\n",
    "                normalize_value['latitude']=i['latitude']\n",
    "                normalize_value['longitude']=i['longitude']\n",
    "\n",
    "\n",
    "                #Resultant Dataframe\n",
    "                df = pd.concat([df,normalize_value],ignore_index=False)\n",
    "\n",
    "        #Converting the data type of cityId from float to numeric\n",
    "        df[\"cityId\"]= pd.to_numeric(df[\"cityId\"])\n",
    "    except Exception as error:\n",
    "        print('Error in data pre-processing', error)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uploading the Dataframe into PostgresSQL; Database Name: Postgres ;Table name : Forecast Air Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_postgres(df,new_collection_name):\n",
    "    try:\n",
    "        #Create instance\n",
    "        engine = postgresEngine\n",
    "        #Intitalize the connection\n",
    "        #connection = engine.connect()\n",
    "        #Upload the dataframe to postgresql\n",
    "        df.to_sql(new_collection_name, engine, if_exists='replace',index=False,method ='multi')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error: \\n\",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Class\n",
    "async def x20148984_AirQuality_Main(isAirqualityCollectionExists):\n",
    "    try:\n",
    "        #Establishing the MongoDB Connection\n",
    "        connection= mongoEngine\n",
    "\n",
    "        global new_col\n",
    "        db = connection[databaseName]\n",
    "        print('inside2')\n",
    "        new_col = db[airQualityTableName]\n",
    "        print('isAirqualityCollectionExists', isAirqualityCollectionExists)\n",
    "        if isAirqualityCollectionExists == False:\n",
    "            #Fetching Data from Open Weather Map API\n",
    "            new_collection=await read_mongo(connection,database_name,existing_collection,new_collection_name,count,delay)\n",
    "        print('Extracted air quality data from mongo')\n",
    "        #Data Pre-Processing and Transformation\n",
    "        finalDf = data_preprocessing(new_col)\n",
    "        print('Performed pre-processing on air quality dataframe', finalDf.shape[0])\n",
    "        #Uploading the dataframe into Postgresql\n",
    "        upload_postgres(df,new_collection_name)\n",
    "    except Exception as error:\n",
    "        print('Error while processing dataframe', error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
